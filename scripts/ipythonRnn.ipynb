{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of utils failed: Traceback (most recent call last):\n",
      "  File \"/home/anaconda3/envs/py3.5/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/anaconda3/envs/py3.5/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/anaconda3/envs/py3.5/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/anaconda3/envs/py3.5/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 626, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 780, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 740, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n",
      "  File \"/root/Gan/jidian/MLexperiments/scripts/utils.py\", line 137\n",
      "    np_input, labelData = np.concatenate((qinshang_man_input)), np.concatenate((qinshang_man_label))\n",
      "    ^\n",
      "IndentationError: unexpected indent\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1f08c7d20460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmyDataSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_Ftest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Ftest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gan/jidian/MLexperiments/scripts/utils.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot, test_size, validation_size, augment, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gan/jidian/MLexperiments/scripts/utils.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(_path, key)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_elems\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_elems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmin_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0muse_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubsample_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/envs/py3.5/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mMR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mmdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatfile_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/envs/py3.5/lib/python3.5/site-packages/scipy/io/matlab/mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m/home/anaconda3/envs/py3.5/lib/python3.5/site-packages/scipy/io/matlab/mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    250\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         '''\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, InputLayer\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import sys\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "sys.path.append(\"/root/Gan/jidian/MLexperiments\")\n",
    "sys.path.append(\"/root/Gan/jidian\")\n",
    "sys.path.append(pwd)\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import MLexperiments.classes\n",
    "from MLexperiments.classes import ReadAutoLabeledData\n",
    "import tensorflow as tf\n",
    "import MLexperiments.config.parameters\n",
    "from keras.layers import LSTM, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4\"\n",
    "CHECKPOINTPATH = 'logs/{}/Rnn_weights.hdf5'.format(time())\n",
    "\n",
    "FLAGS = None\n",
    "myDataSet = utils.read_data_sets(one_hot=True, test_size = 0.1, validation_size = 0.1,fake_data = False)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) , (X_Ftest, y_Ftest)= (myDataSet.train.images, myDataSet.train.labels), (myDataSet.validation.images, myDataSet.validation.labels), (myDataSet.test.images, myDataSet.test.labels)\n",
    "\n",
    "print(X_train[0].shape)\n",
    "print(y_train[0])\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT, 1).astype('float32')\n",
    "X_Ftest = X_Ftest.reshape(X_Ftest.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT, 1).astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "\n",
    "def tran_y(y):\n",
    "    y_ohe = np.zeros(2)\n",
    "    if y:\n",
    "        y_ohe[1] = 1\n",
    "    else:\n",
    "        y_ohe[0] = 1\n",
    "    return y_ohe\n",
    "# def tran_y(y):\n",
    "#     return y\n",
    "\n",
    "y_train_ohe = np.array([tran_y(y_train[i]) for i in range(len(y_train))])\n",
    "y_test_ohe = np.array([tran_y(y_test[i]) for i in range(len(y_test))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(utils)\n",
    "imp.reload(MLexperiments.classes.DataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "model = Sequential()\n",
    "#model.add(Input(shape=(MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT, 1)))\n",
    "# model.add(\n",
    "#     Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1),input_shape=(MLexperiments.config.parameters.SAMPLE_LEN,\\\n",
    "#                                                                        MLexperiments.config.parameters.SAMPLE_HEIGHT, 1)\\\n",
    "#            , padding='valid', activation='relu',name=\"conv1\"))\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1),batch_input_shape=(None, MLexperiments.config.parameters.SAMPLE_LEN,\\\n",
    "                                                                       MLexperiments.config.parameters.SAMPLE_HEIGHT, 1)\\\n",
    "           , padding='valid', activation='relu',name=\"conv1\"))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5,name=\"dropout1\"))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu',name=\"conv2\"))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5,name=\"dropout2\"))\n",
    "model.add(Conv2D(32, kernel_size=(10, MLexperiments.config.parameters.SAMPLE_HEIGHT - 4),name=\"conv3\", strides=(1, 1), padding='valid', activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5,name=\"dropout3\"))\n",
    "\n",
    "model.add(Reshape((model.get_layer(\"dropout3\").output_shape[1], model.get_layer(\"dropout3\").output_shape[3]), name = \"reshape\"))\n",
    "\n",
    "model.add(LSTM(128,  name = \"LSTM1\"))\n",
    "\n",
    "model.add(Dense(64, activation='relu', name = \"dense1\"))\n",
    "model.add(Dense(32, activation='relu', name = \"dense2\"))\n",
    "model.add(Dense(2, activation='softmax', name = \"dense3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE=128\n",
    "\n",
    "# a = Input(shape=(MLexperiments.config.parameters.SAMPLE_LEN,\\\n",
    "#                                                                        MLexperiments.config.parameters.SAMPLE_HEIGHT, 1))\n",
    "# #model.add(Input(shape=(MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT, 1)))\n",
    "# # model.add(\n",
    "# #     Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1),input_shape=(MLexperiments.config.parameters.SAMPLE_LEN,\\\n",
    "# #                                                                        MLexperiments.config.parameters.SAMPLE_HEIGHT, 1)\\\n",
    "# #            , padding='valid', activation='relu',name=\"conv1\"))\n",
    "\n",
    "# # x =    Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1)\\\n",
    "# #            , padding='valid', activation='relu',name=\"conv1\")(a)\n",
    "# x = Flatten()(a)\n",
    "\n",
    "# x = Dense(2, activation='softmax', name = \"dense3\")(x)\n",
    "\n",
    "# model = Model(inputs = [a], outputs = [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "lossHistory = LossHistory()\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTPATH, verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),histogram_freq=0, batch_size=BATCH_SIZE, write_graph=True, write_grads=False, \\\n",
    "                          write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "model.summary()\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8,7\"\n",
    "\n",
    "history = model.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=10, batch_size=BATCH_SIZE, \\\n",
    "                callbacks=[\\\n",
    "                           lossHistory,\\\n",
    "                           checkpointer,\\\n",
    "                           tensorboard\\\n",
    "                          ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(lossHistory.acc)\n",
    "plt.plot(lossHistory.val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('batch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(lossHistory.losses)\n",
    "plt.plot(lossHistory.val_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('batch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "scores = model.evaluate(X_test, y_test_ohe, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for index in range(10):\n",
    "    print(\"expected: \"+str( y_Ftest[index]))\n",
    "    prediction = model.predict(np.expand_dims(X_Ftest[index], axis=0))[0]\n",
    "    print(\"prediction:\" + str(np.argmax(prediction,axis = 0)))\n",
    "    time_series = X_Ftest.reshape(X_Ftest.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT) \\\n",
    "        .astype('float32')[index]\n",
    "    # plt.imshow( X_train.reshape(X_train.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT).astype('float32')[0]);\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    plt.plot(time_series.T[0])\n",
    "    plt.plot(time_series.T[1])\n",
    "    plt.plot(time_series.T[2])\n",
    "    plt.plot(time_series.T[3])\n",
    "    plt.plot(time_series.T[4])\n",
    "    plt.plot(time_series.T[5])\n",
    "    plt.plot(time_series.T[6])\n",
    "    plt.plot(time_series.T[7])\n",
    "    plt.plot(time_series.T[8])\n",
    "    plt.plot(time_series.T[9])\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#        vertical_flip=False,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# index = 0\n",
    "# time_series = X_test.reshape(X_test.shape[0], MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT) \\\n",
    "#         .astype('float32')[index]\n",
    "\n",
    "# # plt.plot(time_series.T[0])\n",
    "# # plt.show()    \n",
    "# # plt.plot(time_series.T[1])\n",
    "# # plt.show()    \n",
    "# # plt.plot(time_series.T[2])\n",
    "# # plt.show()    \n",
    "# # plt.plot(time_series.T[3])\n",
    "# # plt.show()    \n",
    "# # plt.plot(time_series.T[4])\n",
    "# # plt.show()    \n",
    "# # plt.plot(time_series.T[5])\n",
    "# # plt.show()    \n",
    "# # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")    \n",
    "    \n",
    "    \n",
    "# # img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\n",
    "# # x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "# # x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "# x = time_series.reshape((1,)+time_series.shape + (1,))\n",
    "# print(\"x.shape  \")\n",
    "# print(x.shape)\n",
    "# # the .flow() command below generates batches of randomly transformed images\n",
    "# # and saves the results to the `preview/` directory\n",
    "# i = 0\n",
    "# for batch in datagen.flow(x, batch_size=1):\n",
    "#     i += 1\n",
    "#     time_series = batch[0]\n",
    "#     time_series = time_series.reshape( MLexperiments.config.parameters.SAMPLE_LEN, MLexperiments.config.parameters.SAMPLE_HEIGHT) \\\n",
    "#         .astype('float32')\n",
    "#     plt.plot(time_series.T[0])\n",
    "#     plt.plot(time_series.T[1])\n",
    "#     plt.plot(time_series.T[2])\n",
    "#     plt.plot(time_series.T[3])\n",
    "#     plt.plot(time_series.T[4])\n",
    "#     plt.plot(time_series.T[5])\n",
    "#     plt.show()\n",
    "# #     plt.plot(time_series.T[0])\n",
    "# #     plt.show()    \n",
    "# #     plt.plot(time_series.T[1])\n",
    "# #     plt.show()    \n",
    "# #     plt.plot(time_series.T[2])\n",
    "# #     plt.show()    \n",
    "# #     plt.plot(time_series.T[3])\n",
    "# #     plt.show()    \n",
    "# #     plt.plot(time_series.T[4])\n",
    "# #     plt.show()    \n",
    "# #     plt.plot(time_series.T[5])\n",
    "# #     plt.show()    \n",
    "# #     print(\"+++++++++++++++++++++++++++++++++++++++++++++\")    \n",
    "    \n",
    "#     if i > 3:\n",
    "#         break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
